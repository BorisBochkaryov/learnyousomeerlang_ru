\chapter{Путеводитель по параллелизму для путешествующих автостопом}
\label{the-hitchhikers-guide-to-concurrency}
Далеко\--далеко в закоулках нефешенебельного начала 21\--го века, которого даже нет на карте, находится маленькое подмножество человеческих знаний.

В этом подмножестве заключена совершенно невзрачная маленькая дисциплина, чья Фон\--Неймановская архитектура столь примитивна, что согласно ей ОПЗ калькуляторы считаются чем\--то выдающимся.

У этой дисциплины есть, а точнее была \--- проблема: большинство людей, изучающих её, были почти всегда недовольны, создавая параллельное ПО.
Предлагалось множество решений этой проблемы, но чаще всего они были связаны с манипуляцией маленькими логическими блоками, которые назывались локами, мутексами и всякими другими именами, что несколько странно, поскольку этим самым блокам параллелизм был совершенно не нужен.

Так проблема и оставалась нерешённой: одни люди были жадными, другие жалкими, и даже ОПЗ калькуляторы им не помогали.

Кое\--кто был убеждён, что людям не стоило добавлять параллелизм в языки программирования.
И что программы вообще не должны были выходить из их первоначального потока.
\\
\colorbox{lgray}
{
\begin{minipage}{1.0\linewidth}
    \textbf{Замечание:} неплохое развлечение \--- писать пародии на <<Путеводитель по галактике для путешествующих автостопом>>.
    Если вам ещё не попадалась эта книга, то обязательно её прочитайте.
    Она стоит того!
\end{minipage}
}
\section{Без паники}
\label{dont-panic}
\begin{wrapfigure}{l}{0.35\linewidth}
    \includegraphics[width=1\linewidth]{fat-guy.png}
\end{wrapfigure}
Привет.
Сегодня (или в любой из дней, когда вы читаете эти строки, даже завтра) я хочу рассказать вам о параллельном Erlang.
Скорее всего вы уже читали о параллелизме, или когда\--либо сталкивались с ним.
Может быть, вы интересуетесь истоками программирования для множества ядер, или читаете эту книгу, наслушавшись болтовни, которой в наше время окружён параллелизм.

Впрочем, хочу вас предупредить, что в этой главе основной упор сделан на теорию.
Если у вас болит голова, или вы питаете отвращение к истории языков программирования, или вам просто хотелось попрограммировать, то перейдите лучше к ~\ref{thanks-for-all-the-fish}~концу главы, или сразу к следующей (там как раз освещается более практическая сторона вопроса).

Я уже объяснил во введении к книге, что параллелизм в Erlang основан на передаче сообщений и модели акторов.
Мой пример рассказывал о людях, общение которых происходит исключительно при помощи писем.
Чуть позже я ещё вернусь к этой модели, а сейчас нам необходимо первым делом обозначить разницу между \emph{конкурентностью} и \emph{параллелизмом}.

Оба слова во многих ситуациях имеют одно и то же значение.
Но в контексте Erlang они часто относятся к двум разным концепциям.
По мнению большинства эрлангистов понятие конкурентности описывает несколько акторов, которые исполняются независимо друг от друга, но их исполнение не обязательно происходит в один тот же момент.
Параллелизм же означает, что несколько акторов исполняются одновременно.
Взгляды различных областей computer science на правильность этих определений могут не совпадать, но в этом руководстве я буду пользоваться именно такими определениями.
Не удивляйтесь, если в других источниках вы увидите, как кто\--то употребляет те же самые термины для обозначения других понятий.

Конкурентность была в Erlang с самого начала, даже в восьмедисятые, когда всё запускалось на одноядерном процессоре.
Каждому процессу Erlang для исполнения отводился свой собственный временной отрезок, совсем как в эру десктопных приложений, которая предшествовала появлению многоядерных систем.

Уже в то время можно было, в принципе, реализовать параллелизм.
Для этого нам бы потребовался второй компьютер, который бы исполнял код и обменивался информацией с первым.
Но даже такая система могла бы исполнять параллельно всего лишь два актора.
Современные многоядерные системы позволяют реализовать параллелизм в рамках одного компьютера (некоторые промышленные чипы могут содержать десятки ядер), и Erlang использует эту возможность в полной мере.\\
\colorbox{lorange}
{
\begin{minipage}{1.0\linewidth}
    \textbf{Не забывайтесь:}\\
    Важно понимать разницу между конкурентностью и параллелизмом.
    Многие программисты верят, что Erlang был готов к использованию на многоядерных компьютерах задолго до того, как это произошло в действительности.
    Erlang стал использовать истинную \href{http://en.wikipedia.org/wiki/Symmetric\_multiprocessing}{симметричную мультипроцессорность} (symmetric multiprocessing) лишь в середине двухтысячных, а большая часть реализации была завершена в релизе R13B в 2009 году.
    До этого часто приходилось отключать SMP, чтобы избежать потерь производительности.
    На многоядерном компьютере без SMP можно получить параллелизм, если запустить одновременно несколько экземпляров виртуальной машины.\\
    \\
    Интересно отметить, что для внесения истинного параллелизма в язык, не потребовалось производить какие\--либо концептуальные изменения на языковом уровне.
    Благодаря тому, что конкурентность в Erlang строится вокруг изолированных процессов, все изменения были сделаны внутри ВМ, подальше от глаз обычного программиста.
\end{minipage}
}
\section{Принципы конкурентности}
\label{concepts-of-concurrency}
\begin{wrapfigure}{r}{0.35\linewidth}
    \includegraphics[width=1\linewidth]{erlang-the-movie.png}
\end{wrapfigure}
Когда\--то разработка языка Erlang проходила в быстром темпе, и от инженеров, которые занимались разработкой на Erlang для телефонных коммутаторов, поступал плотный поток обратной связи.
Их отчёты подтвердили, что конкурентность, основанная на процессах, и асинхронная передача сообщений позволяли хорошо моделировать задачи, возникающие перед разработчиками.
Кроме того, ещё до появления Erlang, в мире телефонии уже сформировалась некая культура, тяготеющая к параллелизму.
Она была унаследована от языка PLEX, который ранее был создан в Ericsson, и использовался в коммутаторах AXE.
Erlang унаследовал эту тенденцию, и попытался усовершенствовать существующие инструменты.

Для того, чтобы Erlang считался хорошим инструментом, он должен был удовлетворять нескольким требованиям.
Главным условием была возможность масштабирования и поддержки тысяч и тысяч пользователей на множестве коммутаторов.
И эти коммутаторы должны были обеспечивать высокую надёжность работы \--- вплоть до того, что исполнение кода никогда не должно было останавливаться.

\subsection{Масштабируемость}
\label{scalability}
Для начала я расскажу о масштабировании.
Для достижения масштабируемости была необходима система, обладающая определёнными свойствами.
В такой системе пользователи были бы представлены при помощи процессов, которые реагируют на определённые события (например, приём звонка, завершение разговора и т.д.).
Идеальная система должна поддерживать процессы, выполняющие малые объёмы вычислений, и быстрое переключение между процессами при поступлении событий. 
Высокоэффективная обработка процессов предполагала возможность их очень быстрого старта, очень быстрого уничтожения, и очень быстрой коммутации.
Обязательным условием для такого поведения была легковесность процессов.
Это было также необходимо, чтобы избавиться от наличия пула процессов (фиксированное множество процессов, между которыми распределяется работа).
Намного легче создавать программы, которые используют сразу столько процессов, сколько нужно.

Ещё один важный аспект масшабируемости \--- это возможность преодоления ограниченности ресурсов оборудования.
Для решения этой задачи выделяют два направления: можно улучшать характеристики оборудования, а можно увеличивать его количество.
Первое решение будет работать до определённого момента, после которого за улучшение придётся очень дорого платить (необходимо, например, покупать суперкомпьютер).
Второе решение, как правило, обходится дешевле.
Для выполнения тех же задач нужно просто добавлять больше компьютеров.
Вот где вашему языку может пригодиться распределённость.

Вернёмся к обсуждению лёгких процессов.
Высокая надёжность очень важна для нужд телефонии, поэтому разработчики решили, что правильнее всего будет запретить процессам иметь общую память.
Некоторые аварийные ситуации с участием разделяемой памяти могут привести к противоречивому состоянию (особенно если данные разделяются между несколькими узлами) и осложнениям.
Вместо этого процессы должны общаться при помощи сообщений, которые содержат полные копии данных.
Этим мы рискуем получить более медленное, но зато более надёжное решение.
\subsection{Устойчивость к сбоям}
\label{fault-tolerance}
Мы приходим ко второму требованию, которому должен соответствовать Erlang: надёжность.
Первые разработчики на Erlang всегда помнили о том, что сбои происходят повсеместно.
Можно сколько угодно пытаться предотвратить ошибки, но в большинстве случаев от некоторых из них не получится избавиться полностью.
И даже если не будет ошибок \--- от сбоев оборудования никуда не денешься.
Поэтому вместо того, чтобы пытаться полностью предотвратить ошибки, лучше найти хороший способ их обрабатывать.

Оказывается, что подход к проектированию при помощи множественных процессов с передачей сообщений, оказался верным, так как в него можно относительно легко встроить обработку ошибок.
Возьмём, к примеру, легковесные процессы (созданные для быстрых перезапусков и выключений).
Исследования показали, что для масштабных программных комплексов главным источником простоя являются ошибки, которые нерегулярно себя проявляют и спонтанно исчезают (\href{http://dslab.epfl.ch/pubs/crashonly/}{источник}).
Существует правило, говорящее что ошибки, которые искажают данные, должны как можно быстрее приводить к остановке неисправной части системы, чтобы предотвратить проникновение ошибок и плохих данных в остальные узлы.
Есть также ещё одна концепция, согласно которой существует множество различных способов остановки системы.
Двумя такими способами являются корректная остановка и сбой (завершение, вызванное непредвиденной ошибкой).

Очевидно, что наихудшим исходом будет сбой.
Для надёжного устранения проблемы сбоев можно сделать так, чтобы все аварийные ситуации проходили так же, как и корректные остановки.
Для этого необходимо использовать ряд методов, к которым можно отнести принцип неразделяемости ресурсов (shared-nothing) и единичное присваивание (single assignment) (которое позволяет изолировать память процесса), уход от \href{http://en.wikipedia.org/wiki/Lock_(computer_science)}{блокировок} (после аварии блокировка может остаться закрытой, и будет перекрывать другим процессам доступ к данным, или просто приводить данные в нестабильное состояние), а также другие техники, которые я не буду подробно описывать, но они также использовались при проектировании Erlang.
Таким образом, идеальным решением аварийной ситуации в Erlang считается быстрое уничтожение процессов, которое позволяет избежать порчи данных и случайных, нерегулярных ошибок.
Ключевым элементом этой схемы являются лёгкие процессы.
В языке также присутствуют механизмы обработки ошибок, которые позволяют процессам следить за другими процессами (подробнее о них в главе \ref{errors-and-processes}~Ошибки и процессы), определять момент смерти процесса и планировать действия, связанные с этим событием.

Предположим, что быстрый перезапуск процессов позволил нам справиться с аварийными ситуациями.
Следующая проблема \--- сбои оборудования.
Как же сделать так, чтобы программа работала даже тогда, когда кто\--то пинает ногами компьютер, на котором она запущена?
Сложнейший защитный механизм, состоящий из лазерных детекторов и стратегически расставленных кактусов, конечно же, проработает какое\--то время, но надолго его не хватит.
Напрашивается мысль, что можно просто запустить программу сразу на нескольких компьютерах.
Ведь мы это и так уже делаем при масштабировании.
Вот вам и ещё одно преимущество независимых процессов, единственным средством коммуникации которых является передача сообщений.
Они будут работать одинаково и на локальном и на удалённом компьютере.
Такая отказоустойчивость посредством распределённости будет работать практически без участия программиста.
\begin{wrapfigure}{l}{0.35\linewidth}
    \includegraphics[width=1\linewidth]{cacti-laser.png}
\end{wrapfigure}

Распределённость напрямую влияет на общение процессов между собой.
Мы не можем быть уверены, что если узел (удалённый компьютер) существовал в момент вызова функции, то он будет существовать и во время передачи вызова, и что вызов вообще будет правильно выполнен.
Это одно из самых серьёзных препятствий для внедрения распределённости.
Если кто\--то споткнётся о кабель питания или выключит компьютер, то ваше приложение зависнет.
А может быть оно аварийно завершится.
Кто знает?

Выбор асинхронной передачи сообщений, оказывается, тоже был верным шагом.
Cогласно модели "процессы с асинхронной передачей сообщений", сообщения передаются от одного процесса к другому и хранятся в почтовом ящике принимающего процесса до тех пор, пока они не будут извлечены и прочитаны.
При отсылке сообщения мы даже не проверяем, что получающий процесс существует, так как пользы от этой проверки нет никакой.
Как сказано в предыдущем абзаце, невозможно узнать заранее, что за время, прошедшее между отсылкой сообщения и его получением, не случится аварийное завершение процесса.
А если сообщение всё же получено, то невозможно узнать, что процесс\--получатель хоть как\--то отреагирует на сообщение, или вообще доживёт до этого момента.
Асинхронные сообщения позволяют безопасно вызывать удалённые функции, так как не делают никаких прогнозов о возможном развитии событий.
Прогнозы  должен делать программист.
Если вам нужно подтвердить факт доставки, то в ответ необходимо послать оригинальному процессу подтверждающее сообщение.
Для сообщения, а также для любой программы или библиотеки, построенной на этом принципе, будут выполняться те же самые принципы безопасности.
\subsection{Реализация}
\label{implementation}
В общем, было принято решение, что легковесные процессы с асинхронной передачей сообщений полностью подходят Erlang.
Как теперь всё это заставить работать?
Ну, во\--первых, нельзя доверять операционной системе управление процессами.
Операционные системы имеют слишком много методов регуляции процессов, причём эти методы очень сильно различаются по своей производительности.
Большинство методов, если не все, слишком медленны или слишком тяжелы для нужд стандартных областей применения Erlang.
Перенося эти механизмы регуляции внутрь VM, разработчики Erlang сохраняют контроль над оптимизацией и надёжностью.
Современный процесс Erlang занимает около 300 слов памяти, и может создаваться за микросекунды.
В большинстве сегодняшних операционных систем такое не увидишь.

\begin{wrapfigure}{r}{0.35\linewidth}
    \includegraphics[width=1\linewidth]{schedulers.png}
\end{wrapfigure}
Чтобы справляться с множеством потенциальных процессов, которые может создать ваша программа, VM создаёт по одному потоку на каждое ядро.
Эти потоки будут выполнять функцию \emph{планировщика} (scheduler).
Каждый планировщик обслуживает \emph{очередь исполнения} (run queue), которая представляет собой список процессов Erlang, между которыми распределяются отрезки времени.
Когда в очереди исполнения какого\--либо из планировщиков появляется слишком много задач, часть из них переносят в другую очередь.
Так что каждая виртуальная машина Erlang самостоятельно осуществляет балансировку нагрузки, и программиста это не должно беспокоить.
Выполняются также и другие оптимизации, например ограничение частоты отсылки сообщений перегруженным процессам, что позволяет регулировать и перераспределять нагрузку.

Всё самое сложное будет делать вместо вас вирутальная машина.
Именно благодаря этой автоматизации в Erlang можно легко перейти к параллельному исполнению задач.
Переход к параллельному исполнению означает, что скорость работы вашей программы возрастёт в два раза, если вы добавите второе вычислительное ядро, в четыре раза, если добавить ещё 4 и так далее, правильно?
Не всегда.
Такой рост скорости, зависящий от количества ядер или процессоров, называется \emph{линейным масштабированием} (linear scaling) (см. график ниже).
К сожалению, в реальности не бывает бесплатных обедов (бывают на похоронах, но за них всё равно кто\--то платит).
\section{Почти линейное масштабирование, но не совсем}
\label{not-entirely-unlike-linear-scaling}
Линейное масштабирование трудно осуществлять не из\--за самого языка, а из\--за природы решаемых задач.
О задачах, которые очень хорошо масштабируются, иногда говорят, что они \emph{очевидно  параллельны} (embarassingly parallel).
Если вы поищете в Интернет очевидно параллельные задачи, то скорее всего наткнётесь на примеры алгоритмов трассировки лучей (ray\--tracing) (метод создания 3D изображений), поиска грубой силой в криптографии, предсказания погоды и т.д.

Время от времени на IRC каналах, форумах или почтовых рассылках появляются люди с вопросом, можно ли применять Erlang для решения таких задач, и можно ли при этом использовать \href{http://en.wikipedia.org/wiki/Graphics_Processing_Unit}{GPU}.
Ответ на этот вопрос почти всегда отрицательный, и причина для этого сравнительно проста: все эти задачи обычно решаются при помощи численных алгоритмов, перемалывающих большие объёмы данных.
Erlang справляется с такими задачами не очень хорошо.

Задачи, которые являются очевидно параллельными для Erlang, относятся к более высокому логическому уровню.
Обычно они связаны с такими понятиями как чат\--серверы, телефонные коммутаторы, веб\--серверы, очереди сообщений, поисковые роботы, ну или любые другие задачи, в которых действия могут быть представлены как независимые логические элементы (кто\--нибудь вспомнил об акторах?).
Такой тип задач можно эффективно решать с масштабированием, приближающимся к линейному.

Но для некоторых задач такие характеристики масштабирования недостижимы.
Если в решении присутствует одна централизованная последовательность операций, то о линейности масштабирования можно забыть.
\textbf{Ваша параллельная программа не может работать быстрее, чем её самая медленная последовательная часть.}
Пример такого феномена можно наблюдать при любом походе в супермаркет.
Сотни людей могут одновременно выбирать товары в зале, при этом почти не мешая друг другу.
Но если количество покупателей превышает число кассиров, то при оплате покупок сразу образуются очереди.

Можно было бы добавлять кассиров до тех пор, пока на каждого покупателя не будет приходиться по одному кассиру, но тогда вам придётся для каждого покупателя добавлять и собственную дверь, потому что они не смогут все одновременно входить и выходить из магазина.

Иначе говоря, хоть покупатели и могли выбирать необходимые товары параллельно, и это отнимало бы столько же времени, сколько нужно для выбора товаров в одиночестве, но в конце концов им всё равно пришлось бы ожидать своей очереди на пути к кассе.

В обобщённом виде этот принцип называется \href{http://en.wikipedia.org/wiki/Amdahl\%27s_law}{законом Амдала}.
Он демонстрирует ускорение, которое можно ожидать от системы после добавления параллелизма, учитывая соотношение объёма параллельного и последовательного кода:

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{amdahl.png}
\end{figure}
Согласно закону Амдала, код параллельный на 50\% никогда не сможет стать быстрее более чем в два раза, а код параллельный на 95\% теоретически может работать в 20 раз быстрее, при наличии достаточного количества процессоров.
Интересно видеть на этом графике, что удаление последних непараллельных частей программы теоретически даст огромный прирост скорости, по сравнению с удалением последовательного кода из программы, которая и до удаления была не очень\--то параллельной.\\
\colorbox{lorange}
{
\begin{minipage}{1.0\linewidth}
    \textbf{Не забывайтесь:}\\
    Параллелизмом \emph{не получится} решить любую проблему.
    В некоторых случаях добавление параллелизации замедлит ваше приложение.
    Это может случиться, если ваша программа на 100\% состоит из последовательного кода, но при этом пытается использовать несколько процессов.\\
    \\
    Одним из лучших примеров такого поведения является \emph{кольцевой тест} (ring benchmark).
    В этом тесте несколько тысяч процессов последовательно по кругу передают друг другу данные.
    Это очень похоже на \href{http://en.wikipedia.org/wiki/Telephone_game}{игру в телефон}, если такая аналогия вам покажется знакомой.
    В этом тесте в каждую единицу времени лишь один процесс выполняет полезную работу, но виртуальная машина Erlang в это время всё равно не прекращает распределять нагрузку между ядрами, и отдаёт каждому процессу положенную ему часть времени.\\
    \\
    Такая ситуация оказывает негативный эффект на множество оптимизаций, применяемых в оборудовании, и заставляет виртуальную машину тратить время на бесполезные вычисления.
    Зачастую это приводит к тому, что приложение, полностью состоящее из последовательного кода, исполняется на нескольких ядрах значительно медленнее, чем на одном.
    В таком случае не помешает отключить симметричную мультипроцессорность (\ops{\$ erl -smp disable}).
\end{minipage}
}
